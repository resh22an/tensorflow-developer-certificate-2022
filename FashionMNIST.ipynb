{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('TkAgg')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train =  (60000, 28, 28) (60000,)\n",
      "Test =  (60000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "print(\"Train = \", x_train.shape, y_train.shape)\n",
    "print(\"Test = \", x_train.shape, y_test.shape)\n",
    "plt.imshow(x_train[10],cmap='gray')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Missing values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (Missing values) =  False , False\n"
     ]
    }
   ],
   "source": [
    "print(\"Train (Missing values) = \", np.isnan(x_train).any(), \",\", np.isnan(y_train).any())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Categorical/Text features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (Datatype) =  uint8 , uint8\n"
     ]
    }
   ],
   "source": [
    "print(\"Train (Datatype) = \", x_train.dtype, \",\", x_test.dtype)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Feature scaling (Normalization)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0             1             2             3             4    \\\n",
      "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
      "mean       0.000800      0.005783      0.030083      0.103800      0.249683   \n",
      "std        0.092554      0.249033      0.767868      2.512017      4.331376   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max       16.000000     36.000000    119.000000    164.000000    224.000000   \n",
      "\n",
      "                5             6             7             8             9    \\\n",
      "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
      "mean       0.414717      0.821667      2.224733      5.698667     14.434650   \n",
      "std        5.827394      8.309935     14.201820     23.835980     38.204702   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max      230.000000    221.000000    221.000000    254.000000    255.000000   \n",
      "\n",
      "       ...           774           775           776           777  \\\n",
      "count  ...  60000.000000  60000.000000  60000.000000  60000.000000   \n",
      "mean   ...     34.564367     23.208633     16.576250     17.831967   \n",
      "std    ...     57.557779     48.881430     42.044318     43.911297   \n",
      "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "75%    ...     57.000000      8.000000      0.000000      0.000000   \n",
      "max    ...    255.000000    255.000000    255.000000    255.000000   \n",
      "\n",
      "                778           779           780           781           782  \\\n",
      "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
      "mean      22.918850     17.916900      8.485717      2.706333      0.819000   \n",
      "std       51.928401     45.173634     29.448614     17.258682      9.133252   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
      "\n",
      "                783  \n",
      "count  60000.000000  \n",
      "mean       0.070883  \n",
      "std        2.075829  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        0.000000  \n",
      "75%        0.000000  \n",
      "max      170.000000  \n",
      "\n",
      "[8 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "x_train_temp = np.reshape(x_train, (x_train.shape[0], -1))\n",
    "x_test_temp = np.reshape(x_test, (x_test.shape[0], -1))\n",
    "print(pd.DataFrame(x_train_temp).describe())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized => Min (Train) =  0.0  and Max (Train) =  1.0\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train/255 #(x_train-0)/(255-0)\n",
    "x_test = x_test/255 #(x_test-0)/(255-0)\n",
    "print(\"Normalized => Min (Train) = \",np.min(x_train),\" and Max (Train) = \",np.max(x_train))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Build MODEL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "callback_es = tf.keras.callbacks.EarlyStopping(monitor='loss',patience=3)\n",
    "class AccCheck(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs['accuracy'] >= 0.95:\n",
    "            print(\"Reached 99.5% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "fm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu',input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=10, activation='softmax')\n",
    "])\n",
    "\n",
    "fm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 13, 13, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               102528    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,922\n",
      "Trainable params: 122,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fm_model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.4554 - accuracy: 0.8351\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.3077 - accuracy: 0.8887\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.2631 - accuracy: 0.9028\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.2368 - accuracy: 0.9113\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.2108 - accuracy: 0.9208\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.1923 - accuracy: 0.9278\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.1748 - accuracy: 0.9344\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 578s 308ms/step - loss: 0.1583 - accuracy: 0.9402\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 38s 21ms/step - loss: 0.1453 - accuracy: 0.9454\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.1318 - accuracy: 0.9506Reached 99.5% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.1318 - accuracy: 0.9506\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x15e9510a0>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_model.fit(x_train, y_train, epochs=10, callbacks=[callback_es,AccCheck()])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2715 - accuracy: 0.9126\n",
      "Loss, Accuracy (Test) =  [0.2714907228946686, 0.9125999808311462]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss, Accuracy (Test) = \", fm_model.evaluate(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Predict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step\n",
      "Predictions (sample) =  ['Trouser', 'Pullover', 'Coat', 'Bag', 'T-shirt/top']\n"
     ]
    }
   ],
   "source": [
    "def predict_labels(pred_arr):\n",
    "    idx = np.argmax(pred_arr, axis=1)  # Row-wise\n",
    "    labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    return [labels[i] for i in idx]\n",
    "\n",
    "y_pred = fm_model.predict(x_test)\n",
    "print(\"Predictions (sample) = \", predict_labels(y_pred[15:20]))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
